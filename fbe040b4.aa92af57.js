(window.webpackJsonp=window.webpackJsonp||[]).push([[30],{84:function(e,t,r){"use strict";r.r(t),r.d(t,"frontMatter",(function(){return c})),r.d(t,"metadata",(function(){return l})),r.d(t,"rightToc",(function(){return s})),r.d(t,"default",(function(){return b}));var a=r(2),n=r(6),o=(r(0),r(90)),i=r(92),c={id:"moving-databricks-from-one-azure-subscription-to-another",title:"Moving Databricks from one Azure subscription to another",author:"Jaco Jansen van Vuuren",author_title:"Software Developer",author_url:"https://github.com/jacojvv-dev",author_image_url:"https://avatars0.githubusercontent.com/u/14131955?v=4",tags:["azure","databricks"]},l={permalink:"/blog/moving-databricks-from-one-azure-subscription-to-another",editUrl:"https://github.com/jacojvv-dev/jacojvv.dev/edit/main/blog/2020-08-17-moving-databricks-from-one-azure-subscription-to-another.md",source:"@site/blog\\2020-08-17-moving-databricks-from-one-azure-subscription-to-another.md",description:"I recently needed to move the Databricks instance at immedia from one Azure subscription to another - online resources on this topic were scarce - so I thought I could contribute a little something to the world. Hopefully it's useful to someone.",date:"2020-08-17T00:00:00.000Z",tags:[{label:"azure",permalink:"/blog/tags/azure"},{label:"databricks",permalink:"/blog/tags/databricks"}],title:"Moving Databricks from one Azure subscription to another",readingTime:3.96,truncated:!0,nextItem:{title:"A case for a lower footprint JSON specification",permalink:"/blog/a-case-for-a-lower-footprint-json-specification"}},s=[{value:"Can&#39;t I just change the subscription?",id:"cant-i-just-change-the-subscription",children:[]},{value:"Before we start - navigating and downloading files from the databricks filesystem",id:"before-we-start---navigating-and-downloading-files-from-the-databricks-filesystem",children:[]},{value:"Exporting/Importing the workspace",id:"exportingimporting-the-workspace",children:[]},{value:"Recreate interactive cluster(s)",id:"recreate-interactive-clusters",children:[]},{value:"Export/Import data",id:"exportimport-data",children:[]},{value:"Export/Import checkpoints",id:"exportimport-checkpoints",children:[]},{value:"Other things you&#39;ll need to do",id:"other-things-youll-need-to-do",children:[]}],u={rightToc:s};function b(e){var t=e.components,r=Object(n.a)(e,["components"]);return Object(o.b)("wrapper",Object(a.a)({},u,r,{components:t,mdxType:"MDXLayout"}),Object(o.b)("p",null,"I recently needed to move the Databricks instance at immedia from one Azure subscription to another - online resources on this topic were scarce - so I thought I could contribute a little something to the world. Hopefully it's useful to someone."),Object(o.b)("h3",{id:"cant-i-just-change-the-subscription"},"Can't I just change the subscription?"),Object(o.b)("p",null,"Unfortunately - this is not an option for Databricks - so the only option left is to manually move all your data across. The process is rinse and repeat once you know what to do."),Object(o.b)("h3",{id:"before-we-start---navigating-and-downloading-files-from-the-databricks-filesystem"},"Before we start - navigating and downloading files from the databricks filesystem"),Object(o.b)("p",null,'This is an essential skill needed to follow along - as you\'ll need to download several files from your old instance. By far the easiest way to view your databricks file structure is via the "Data" tab.'),Object(o.b)("p",null,'On the side tab go to "Data" and then click on "Add Data". Once the page loads switch the tab to DBFS.'),Object(o.b)("img",{alt:"Databricks file explorer",src:Object(i.a)("img/moving-databricks/07_file_explorer.png")}),Object(o.b)("p",null,'Everything in the "FileStore" directory can be easily downloaded. For example - if you wanted to download the file from\n',Object(o.b)("em",{parentName:"p"},"/FileStore/cpbak/app_store_huawei_cosmos_v1.zip")," you can go the following url to download it ",Object(o.b)("em",{parentName:"p"},"https://{your-sub-domain}.azuredatabricks.net/files/cpbak/app_store_huawei_cosmos_v1.zip")),Object(o.b)("img",{alt:"Databricks file explorer",src:Object(i.a)("img/moving-databricks/08_file_explorer_file.png")}),Object(o.b)("h3",{id:"exportingimporting-the-workspace"},"Exporting/Importing the workspace"),Object(o.b)("p",null,"First things first - we need to export and import our workspace from the old instance to the new instance."),Object(o.b)("ol",null,Object(o.b)("li",{parentName:"ol"},'On the old instance - export your workspace. Make sure to select "DBC Archive".')),Object(o.b)("img",{alt:"Exporting your workspace",src:Object(i.a)("img/moving-databricks/01_export_workspace.png")}),Object(o.b)("ol",{start:2},Object(o.b)("li",{parentName:"ol"},"On the new instance - start the import.")),Object(o.b)("img",{alt:"Importing your workspace",src:Object(i.a)("img/moving-databricks/02_import_workspace_01.png")}),Object(o.b)("ol",{start:3},Object(o.b)("li",{parentName:"ol"},"Select the .dbc file that was exported during step one and click import.")),Object(o.b)("img",{alt:"Importing your workspace",src:Object(i.a)("img/moving-databricks/03_import_workspace_02.png")}),Object(o.b)("p",null,"Your workbooks will now all be on the new Databricks instance."),Object(o.b)("h3",{id:"recreate-interactive-clusters"},"Recreate interactive cluster(s)"),Object(o.b)("p",null,"The next thing you'll want to to is recreate the cluster that you use for running/testing things interactively - this means all of the following:"),Object(o.b)("ul",null,Object(o.b)("li",{parentName:"ul"},"Selecting the same Spark/Scala/Python versions & sizing it appropriately"),Object(o.b)("li",{parentName:"ul"},"Installing the same jar files or Maven dependencies")),Object(o.b)("ol",null,Object(o.b)("li",{parentName:"ol"},'On the side tab go to "Clusters", then click "Create Cluster", copy the details of your existing cluster over to the new cluster - make sure you keep versions the same so that you don\'t have errors when running your notebooks. When you have filled in the details - click "Create Cluster".')),Object(o.b)("img",{alt:"Cluster setup",src:Object(i.a)("img/moving-databricks/04_cluster_reference.png")}),Object(o.b)("ol",{start:2},Object(o.b)("li",{parentName:"ol"},'Once the cluster is recreated you\'ll need to reinstall any libraries that were installed. On the side tab go to "Clusters", then click on your newly created cluster. When your cluster loads - switch to the library tab.')),Object(o.b)("img",{alt:"Library tab",src:Object(i.a)("img/moving-databricks/05_library_cluster_tab.png")}),Object(o.b)("ol",{start:3},Object(o.b)("li",{parentName:"ol"},"Install any libraries until you match the old instance. Make sure your versions are the same!")),Object(o.b)("img",{alt:"Installed libraries",src:Object(i.a)("img/moving-databricks/06_installed_cluster_libraries.png")}),Object(o.b)("h3",{id:"exportimport-data"},"Export/Import data"),Object(o.b)("p",null,"To export your data - use the following. It will export your data as CSV to the file store so that you can download it."),Object(o.b)("p",null,"You can read more about it ",Object(o.b)("a",Object(a.a)({parentName:"p"},{href:"https://towardsdatascience.com/databricks-how-to-save-files-in-csv-on-your-local-computer-3d0c70e6a9ab"}),"here"),". There are easier options you can use if your dataset is less than a million rows."),Object(o.b)("pre",null,Object(o.b)("code",Object(a.a)({parentName:"pre"},{className:"language-python"}),'data = spark.read.format("delta").table("<delta-table-name>")\ndata.coalesce(1)\n    .write\n    .format("com.databricks.spark.csv")\n    .option("header", "true")\n    .save("dbfs:/FileStore/df/<delta-table-name>.csv")\n')),Object(o.b)("p",null,"After downloading your exported CSV data we can upload it to the new Databricks instance."),Object(o.b)("ol",null,Object(o.b)("li",{parentName:"ol"},'On the side tab go to "Data" and then click on "Add Data". Select the CSV file you just downloaded. Click on "Create Table With UI", select your cluster and then "Preview Table".')),Object(o.b)("img",{alt:"Create new table",src:Object(i.a)("img/moving-databricks/09_create_new_table.png")}),Object(o.b)("ol",{start:2},Object(o.b)("li",{parentName:"ol"},'Make sure your data is parsed correctly. Make sure that your types match the types on your old cluster. When you are happy - click on "Create Table".')),Object(o.b)("img",{alt:"Validate table schema",src:Object(i.a)("img/moving-databricks/10_validate_schema.png")}),Object(o.b)("ol",{start:3},Object(o.b)("li",{parentName:"ol"},"Optional - you can optionally create the database schema using delta and then insert the imported data into that table - this is my preferred method because sometimes the CSV files are more than 2GB large and I need to import several distinct files. Just make sure the table name is different than the delta table when importing.")),Object(o.b)("pre",null,Object(o.b)("code",Object(a.a)({parentName:"pre"},{className:"language-sql"}),"CREATE TABLE tablename (\n  FieldOne      STRING,\n  FieldTwo      STRING)\nUSING DELTA\n\nMERGE INTO tablename t\n    USING tablename_backup_import s\n    ON t.FieldOne = s.FieldOne AND t.FieldTwo = s.FieldTwo\n    WHEN NOT MATCHED THEN INSERT\n        (FieldOne, FieldTwo) VALUES (s.FieldOne, s.FieldTwo)\n")),Object(o.b)("h3",{id:"exportimport-checkpoints"},"Export/Import checkpoints"),Object(o.b)("p",null,"If you use structured streaming - you'll most likely need to move your checkpoints as well."),Object(o.b)("h3",{id:"other-things-youll-need-to-do"},"Other things you'll need to do"),Object(o.b)("ul",null,Object(o.b)("li",{parentName:"ul"},"Set up your jobs"),Object(o.b)("li",{parentName:"ul"},"Make sure the clusters that your jobs use are the same as in the old cluster"),Object(o.b)("li",{parentName:"ul"},"Make sure you have the same schedules for all your jobs"),Object(o.b)("li",{parentName:"ul"},"Make sure everything works after you are finished")),Object(o.b)("p",null,"Good luck! May you Databricks endeavors be epic!"))}b.isMDXComponent=!0},89:function(e,t,r){"use strict";var a=r(0),n=r(21);t.a=function(){const e=Object(a.useContext)(n.a);if(null===e)throw new Error("Docusaurus context not provided");return e}},90:function(e,t,r){"use strict";r.d(t,"a",(function(){return b})),r.d(t,"b",(function(){return h}));var a=r(0),n=r.n(a);function o(e,t,r){return t in e?Object.defineProperty(e,t,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[t]=r,e}function i(e,t){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),r.push.apply(r,a)}return r}function c(e){for(var t=1;t<arguments.length;t++){var r=null!=arguments[t]?arguments[t]:{};t%2?i(Object(r),!0).forEach((function(t){o(e,t,r[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):i(Object(r)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(r,t))}))}return e}function l(e,t){if(null==e)return{};var r,a,n=function(e,t){if(null==e)return{};var r,a,n={},o=Object.keys(e);for(a=0;a<o.length;a++)r=o[a],t.indexOf(r)>=0||(n[r]=e[r]);return n}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)r=o[a],t.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(n[r]=e[r])}return n}var s=n.a.createContext({}),u=function(e){var t=n.a.useContext(s),r=t;return e&&(r="function"==typeof e?e(t):c(c({},t),e)),r},b=function(e){var t=u(e.components);return n.a.createElement(s.Provider,{value:t},e.children)},p={inlineCode:"code",wrapper:function(e){var t=e.children;return n.a.createElement(n.a.Fragment,{},t)}},d=n.a.forwardRef((function(e,t){var r=e.components,a=e.mdxType,o=e.originalType,i=e.parentName,s=l(e,["components","mdxType","originalType","parentName"]),b=u(r),d=a,h=b["".concat(i,".").concat(d)]||b[d]||p[d]||o;return r?n.a.createElement(h,c(c({ref:t},s),{},{components:r})):n.a.createElement(h,c({ref:t},s))}));function h(e,t){var r=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var o=r.length,i=new Array(o);i[0]=d;var c={};for(var l in t)hasOwnProperty.call(t,l)&&(c[l]=t[l]);c.originalType=e,c.mdxType="string"==typeof e?e:a,i[1]=c;for(var s=2;s<o;s++)i[s]=r[s];return n.a.createElement.apply(null,i)}return n.a.createElement.apply(null,r)}d.displayName="MDXCreateElement"},92:function(e,t,r){"use strict";r.d(t,"b",(function(){return o})),r.d(t,"a",(function(){return i}));var a=r(89),n=r(94);function o(){const{siteConfig:{baseUrl:e="/",url:t}={}}=Object(a.a)();return{withBaseUrl:(r,a)=>function(e,t,r,{forcePrependBaseUrl:a=!1,absolute:o=!1}={}){if(!r)return r;if(r.startsWith("#"))return r;if(Object(n.b)(r))return r;if(a)return t+r;const i=!r.startsWith(t)?t+r.replace(/^\//,""):r;return o?e+i:i}(t,e,r,a)}}function i(e,t={}){const{withBaseUrl:r}=o();return r(e,t)}},94:function(e,t,r){"use strict";function a(e){return!0===/^(\w*:|\/\/)/.test(e)}function n(e){return void 0!==e&&!a(e)}r.d(t,"b",(function(){return a})),r.d(t,"a",(function(){return n}))}}]);